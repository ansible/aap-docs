:_mod-docs-content-type: REFERENCE

[id="lightspeed-intelligent-assistant-variables"]

= Ansible Lightspeed intelligent assistant variables

[role="_abstract"]
Inventory file variables for Ansible Lightspeed intelligent assistant.

[cols="25%,25%,30%,10%,10%",options="header"]
|===
| RPM variable name | Container variable name | Description | Required or optional | Default

| N/A
| `lightspeed_chatbot_model_url`
| The inference API base URL on your LLM setup. For example, `\https://your_inference_api/v1`.
| Optional
|

| N/A
| `lightspeed_chatbot_model_verify_ssl`
| Controls whether SSL/TLS certificate verification is enabled or disabled when making HTTPS requests.
| Optional
| `true`

| N/A
| `lightspeed_chatbot_default_provider`
a| The provider type of your LLM setup by using one of the following values: 

* {RHELAI}: `rhelai`
* {OCPAI}: `rhoai`

| Optional
| `rhoai`

| N/A
| `lightspeed_chatbot_http_port`
| Port number that Ansible Lightspeed intelligent assistant listens on for HTTP requests.
| Optional
| `8085`

| N/A
| `lightspeed_chatbot_model_id`
| The ID of the LLM model that is configured on your LLM setup.
| Optional
|

| N/A
| `lightspeed_chatbot_model_api_key`
| The API token or the API key of your LLM setup. This token is sent along with the authorization header when an inference API is called.
| Optional
|

|===
