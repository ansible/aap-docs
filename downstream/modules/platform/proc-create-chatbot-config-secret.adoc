:_mod-docs-content-type: PROCEDURE

[id="proc-create-chatbot-config-secret"]

= Creating a chatbot configuration secret 

Create a configuration secret for the {AAPchatbot}, so that you can connect the intelligent assistant to the {PlatformNameShort} operator.

.Prerequisites
* link:https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.5/html-single/installing_on_openshift_container_platform/index#proc-install-operator-chatbot[You have installed and configured the {PlatformNameShort} operator].

.Procedure
. Log in to {OCP} as an administrator.
. Navigate to menu:Workloads[Secrets].
. From the *Projects* list, select the namespace that you created when you installed the {PlatformNameShort} operator.
. Click menu:Create[Key/value secret].
. In the *Secret name* field, enter a unique name for the secret. For example, `chatbot-configuration-secret`. 
. Add the following keys and their associated values individually:
+
[%header,cols="25%,75%"]
|====
| Key 
| Value

2+| *Settings for all LLM setups*
|`chatbot_model`
|Enter the LLM model name that is configured on your LLM setup. 

|`chatbot_url`
|Enter the inference API base URL on your LLM setup. For example, `\https://your_inference_api/v1`.  

|`chatbot_token`
|Enter the API token or the API key. This token is sent along with the authorization header when an inference API is called.  

|`chatbot_llm_provider_type`
a|_Optional_

Enter the provider type of your LLM setup by using one of the following values:

* {RHELAI}: `rhelai_vllm` 

* {OCPAI}: `rhoai_vllm`

2+| *Additional settings for MCP server configuration*

* {OpenAI}: `openai`

* {AzureOpenAI}: `azure_openai`

|`chatbot_context_window_size`
a| _Optional_

Enter a value to configure the context window length for your LLM setup.

Default= `128000`

|`chatbot_temperature_override`
a| _Optional_

A lower temperature generates predictable results, while a higher temperature allows more diverse or creative responses.

Enter one of the following values:

* `0`: Least creativity and randomness in the responses.
* `1`: Maximum creativity and randomness in the responses.
* `null`: Override or disable the default temperature setting. 
+
[NOTE]
====
A few {OpenAI} o-series models  (o1, o3-mini, and o4-mini models) do not support the temperature settings. Therefore, you must set the value to null to use these {OpenAI} models.
====

2+| *Additional setting for {IBMwatsonxai} only*

|`chatbot_llm_provider_project_id`
| Enter the project ID of your IBM watsonx setup.

2+| *Additional settings for {AzureOpenAI} only*

|`chatbot_azure_deployment_name`
| Enter the deployment name of your {AzureOpenAI} setup.

|`chatbot_azure_api_version`
| _Optional_

Enter the API version of your {AzureOpenAI} setup.

<<<<<<< HEAD
=======
* If none of these values are configured, no MCP server is provisioned or registered with the underlying LLM's tool at runtime.
* If you configure the `aap_gateway_url` value only, the Ansible Lightspeed Service MCP server is provisioned. Authentication attempts to use the JSON Web Token (JWT) token associated with the user's authenticated context.
* If you configure both values `aap_gateway_url` and `aap_controller_url`, the Ansible Lightspeed Service MCP server and {PlatformNameShort} Controller Service MCP server are both configured. Authentication attempts to use the JWT token associated with the user's authenticated context.
>>>>>>> 1bc7c2a3 (AAP-51490-updates: Self-review updates to Ansible Lightspeed chatbot docs for AAP 2.6 (#4455))
|====

. Click *Create*. The chatbot authorization secret is successfully created.



