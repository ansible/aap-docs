:_mod-docs-content-type: PROCEDURE

[id="proc-create-chatbot-config-secret"]

= Creating a chatbot configuration secret 

[role="_abstract"]

Create a configuration secret for the {AAPchatbot}, so that you can connect the intelligent assistant to the {PlatformNameShort} operator.

.Prerequisites
* link:https://docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/2.6/html-single/installing_on_openshift_container_platform/index#proc-install-operator-chatbot[You have installed and configured the {PlatformNameShort} operator].

.Procedure
. Log in to {OCP} as an administrator.
. Navigate to menu:Workloads[Secrets].
. From the *Projects* list, select the namespace that you created when you installed the {PlatformNameShort} operator.
. Click menu:Create[Key/value secret].
. In the *Secret name* field, enter a unique name for the secret. For example, `chatbot-configuration-secret`. 
. Add the following keys and their associated values individually:
+
[%header,cols="25%,75%"]
|====
| Key 
| Value

2+| *Settings for all LLM setups*
|`chatbot_model`
|Enter the LLM model name that is configured on your LLM setup. 

|`chatbot_url`
|Enter the inference API base URL on your LLM setup. For example, `\https://your_inference_api/v1`.  

|`chatbot_token`
|Enter the API token or the API key. This token is sent along with the authorization header when an inference API is called.  

|`chatbot_llm_provider_type`
a|_Optional_

Enter the value as per the provider type of your LLM setup:

* {RHELAI}: `rhelai_vllm` 

* {OCPAI}: `rhoai_vllm`

* {OpenAI}: `openai`

* {AzureOpenAI}: `azure_openai`

|`chatbot_model_config_extras`
|_Optional_

Use this field to pass a JSON dictionary of extra parameters to pass directly to the model provider, for settings not covered by other standard fields.

For example, you can specify a parameter `api_version` for {AzureOpenAI} in the JSON format `'{"api_version": "<your API version>"}'`.


2+| *Additional settings for MCP server configuration*

a|
* `aap_gateway_url`
* `aap_controller_url`

a|

Configure a Model Context Protocol (MCP) server that interfaces with the {AAPchatbot}. 

The values `aap_gateway_url` and `aap_controller_url` are internal URLs accessible to the {Gateway} and {ControllerName} services on the OpenShift cluster. For example, if the name of your {PlatformNameShort} custom resource is `myaap`, these URLs will be:

* `aap_gateway_url`: `\http://myaap`
* `aap_controller_url`: `\http://myaap-controller-service`

For MCP server configuration:

* If none of these values are configured, no MCP server is provisioned or registered with the underlying LLM's tool at runtime.
* If you configure the `aap_gateway_url` value only, the Ansible Lightspeed Service MCP server is provisioned. Authentication attempts to use the JSON Web Token (JWT) token associated with the user's authenticated context.
* If you configure both values `aap_gateway_url` and `aap_controller_url`, the Ansible Lightspeed Service MCP server and {PlatformNameShort} Controller Service MCP server are both configured. Authentication attempts to use the JWT token associated with the user's authenticated context.
|====

. Click *Create*. The chatbot authorization secret is successfully created.



