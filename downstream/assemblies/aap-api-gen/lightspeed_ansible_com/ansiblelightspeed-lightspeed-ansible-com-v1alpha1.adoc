// Automatically generated by 'openshift-apidocs-gen'. Do not edit.
:_content-type: ASSEMBLY
[id="ansiblelightspeed-lightspeed-ansible-com-v1alpha1"]
= AnsibleLightspeed [lightspeed.ansible.com/v1alpha1]
ifdef::product-title[]
include::modules/common-attributes.adoc[]
endif::[]

toc::[]


Description::
+
--
AnsibleAIConnect is the Schema for the ansibleaiconnects API
--

Type::
  `object`



== Specification

[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `apiVersion`
| `string`
| APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources

| `kind`
| `string`
| Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds

| `metadata`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.ObjectMeta[`ObjectMeta`]
| Standard object's metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata

| `spec`
| `object`
| Spec defines the desired state of AnsibleAIConnect

| `status`
| ``
| Status defines the observed state of AnsibleAIConnect

|===
=== .spec
Description::
+
--
Spec defines the desired state of AnsibleAIConnect
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `additional_labels`
| `array (string)`
| Additional labels defined on the resource, which should be propagated to child resources

| `admin_email`
| `string`
| E-mail address to use for the admin account

| `admin_password_secret`
| `string`
| Secret where the admin password can be found. If not specified, one will be generated.

| `admin_user`
| `string`
| Username to use for the admin account

| `api`
| `object`
| Defines desired state of the resources

| `auth_config_secret_name`
| `string`
| Secret where the authentication configuration can be found

| `bundle_cacert_secret`
| `string`
| Secret where the trusted Certificate Authority Bundle is stored

| `chatbot_api`
| `object`
| Defines desired state of the resources

| `chatbot_config_secret_name`
| `string`
| Secret where the chatbot configuration can be found

| `chatbot_image`
| `string`
| Registry path to Chatbot API container image to use

| `chatbot_image_version`
| `string`
| Chatbot API container image tag or version to use

| `database`
| `object`
| The PostgreSQL database StatefulSet

| `db_fields_encryption_secret`
| `string`
| Secret where the DB fields encryption key can be found. If not specified, one will be generated.

| `extra_settings`
| `array`
| Environment variables to configure the application-level settings

| `extra_settings[]`
| `object`
| 

| `hostname`
| `string`
| The hostname of the instance

| `image`
| `string`
| Registry path to API container image to use

| `image_pull_policy`
| `string`
| The image pull policy

| `image_pull_secrets`
| `array (string)`
| Image pull secrets for the API and database containers

| `image_version`
| `string`
| API container image tag or version to use

| `ingress_annotations`
| `string`
| Annotations to add to the Ingress Controller

| `ingress_api_version`
| `string`
| The Ingress API version to use

| `ingress_class_name`
| `string`
| The name of ingress class to use instead of the cluster default.

| `ingress_path`
| `string`
| The ingress path used to reach the deployed service

| `ingress_path_type`
| `string`
| The ingress path type for the deployed service

| `ingress_tls_secret`
| `string`
| Secret where the Ingress TLS secret can be found

| `ingress_type`
| `string`
| The ingress type to use to reach the deployed instance

| `loadbalancer_port`
| `integer`
| Port to use for the loadbalancer

| `loadbalancer_protocol`
| `string`
| Protocol to use for the loadbalancer

| `model_config_secret_name`
| `string`
| Secret where the model configuration can be found

| `no_log`
| `boolean`
| Configure no_log for no log tasks

| `nodeport_port`
| `integer`
| Port to use for the nodeport

| `postgres_image`
| `string`
| Registry path to the PostgreSQL container to use

| `postgres_image_version`
| `string`
| PostgreSQL container image version to use

| `route_api_version`
| `string`
| The route API version to use

| `route_host`
| `string`
| The DNS to use to points to the instance

| `route_tls_secret`
| `string`
| Secret where the TLS related credentials are stored

| `route_tls_termination_mechanism`
| `string`
| The secure TLS termination mechanism to use

| `service_account_annotations`
| `string`
| ServiceAccount annotations

| `service_annotations`
| `string`
| Service annotations

| `service_type`
| `string`
| The service type to be used on the deployed instance

| `set_self_labels`
| `boolean`
| Maintain some of the recommended `app.kubernetes.io/*` labels on the resource (self)

|===
=== .spec.api
Description::
+
--
Defines desired state of the resources
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `model_pipeline_secret`
| `string`
| Secret where the Model Pipeline configuration can be found. Set this to use your own external configuration. If not specified, this secret will be generated based on the content of the 'model_config_secret_name' Secret.

| `node_selector`
| `object (string)`
| NodeSelector for the pods.

| `replicas`
| ``
| The number of replicas. Default: 1

| `resource_requirements`
| `object`
| Resource requirements for the container.

| `strategy`
| `object`
| The deployment strategy to use to replace existing pods with new ones.

| `tolerations`
| `array`
| Node tolerations for the pods.

| `tolerations[]`
| `object`
| The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.

| `topology_spread_constraints`
| `array`
| Topology rule(s) for the pods.

| `topology_spread_constraints[]`
| `object`
| TopologySpreadConstraint specifies how to spread matching pods among the given topology.

|===
=== .spec.api.resource_requirements
Description::
+
--
Resource requirements for the container.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `claims`
| `array`
| Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
 This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
 This field is immutable.

| `claims[]`
| `object`
| ResourceClaim references one entry in PodSpec.ResourceClaims.

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .spec.api.resource_requirements.claims
Description::
+
--
Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
 This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
 This field is immutable.
--

Type::
  `array`




=== .spec.api.resource_requirements.claims[]
Description::
+
--
ResourceClaim references one entry in PodSpec.ResourceClaims.
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.

|===
=== .spec.api.strategy
Description::
+
--
The deployment strategy to use to replace existing pods with new ones.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `rollingUpdate`
| `object`
| Rolling update config params. Present only if DeploymentStrategyType = RollingUpdate. --- TODO: Update this to follow our convention for oneOf, whatever we decide it to be.

| `type`
| `string`
| Type of deployment. Can be "Recreate" or "RollingUpdate". Default is RollingUpdate.

|===
=== .spec.api.strategy.rollingUpdate
Description::
+
--
Rolling update config params. Present only if DeploymentStrategyType = RollingUpdate. --- TODO: Update this to follow our convention for oneOf, whatever we decide it to be.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `maxSurge`
| `integer-or-string`
| The maximum number of pods that can be scheduled above the desired number of pods. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number is calculated from percentage by rounding up. Defaults to 25%. Example: when this is set to 30%, the new ReplicaSet can be scaled up immediately when the rolling update starts, such that the total number of old and new pods do not exceed 130% of desired pods. Once old pods have been killed, new ReplicaSet can be scaled up further, ensuring that total number of pods running at any time during the update is at most 130% of desired pods.

| `maxUnavailable`
| `integer-or-string`
| The maximum number of pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). Absolute number is calculated from percentage by rounding down. This can not be 0 if MaxSurge is 0. Defaults to 25%. Example: when this is set to 30%, the old ReplicaSet can be scaled down to 70% of desired pods immediately when the rolling update starts. Once new pods are ready, old ReplicaSet can be scaled down further, followed by scaling up the new ReplicaSet, ensuring that the total number of pods available at all times during the update is at least 70% of desired pods.

|===
=== .spec.api.tolerations
Description::
+
--
Node tolerations for the pods.
--

Type::
  `array`




=== .spec.api.tolerations[]
Description::
+
--
The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `effect`
| `string`
| Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.

| `key`
| `string`
| Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.

| `operator`
| `string`
| Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.

| `tolerationSeconds`
| `integer`
| TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.

| `value`
| `string`
| Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.

|===
=== .spec.api.topology_spread_constraints
Description::
+
--
Topology rule(s) for the pods.
--

Type::
  `array`




=== .spec.api.topology_spread_constraints[]
Description::
+
--
TopologySpreadConstraint specifies how to spread matching pods among the given topology.
--

Type::
  `object`

Required::
  - `maxSkew`
  - `topologyKey`
  - `whenUnsatisfiable`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `labelSelector`
| `object`
| LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.

| `matchLabelKeys`
| `array (string)`
| MatchLabelKeys is a set of pod label keys to select the pods over which spreading will be calculated. The keys are used to lookup values from the incoming pod labels, those key-value labels are ANDed with labelSelector to select the group of existing pods over which spreading will be calculated for the incoming pod. Keys that don't exist in the incoming pod labels will be ignored. A null or empty list means only match against labelSelector.

| `maxSkew`
| `integer`
| MaxSkew describes the degree to which pods may be unevenly distributed. When `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference between the number of matching pods in the target topology and the global minimum. The global minimum is the minimum number of matching pods in an eligible domain or zero if the number of eligible domains is less than MinDomains. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 2/2/1: In this case, the global minimum is 1. \| zone1 \| zone2 \| zone3 \| \|  P P  \|  P P  \|   P   \| - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2; scheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. When `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence to topologies that satisfy it. It's a required field. Default value is 1 and 0 is not allowed.

| `minDomains`
| `integer`
| MinDomains indicates a minimum number of eligible domains. When the number of eligible domains with matching topology keys is less than minDomains, Pod Topology Spread treats "global minimum" as 0, and then the calculation of Skew is performed. And when the number of eligible domains with matching topology keys equals or greater than minDomains, this value has no effect on scheduling. As a result, when the number of eligible domains is less than minDomains, scheduler won't schedule more than maxSkew Pods to those domains. If value is nil, the constraint behaves as if MinDomains is equal to 1. Valid values are integers greater than 0. When value is not nil, WhenUnsatisfiable must be DoNotSchedule. 
 For example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same labelSelector spread as 2/2/2: \| zone1 \| zone2 \| zone3 \| \|  P P  \|  P P  \|  P P  \| The number of domains is less than 5(MinDomains), so "global minimum" is treated as 0. In this situation, new pod with the same labelSelector cannot be scheduled, because computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones, it will violate MaxSkew. 
 This is a beta field and requires the MinDomainsInPodTopologySpread feature gate to be enabled (enabled by default).

| `nodeAffinityPolicy`
| `string`
| NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector when calculating pod topology spread skew. Options are: - Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations. - Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations. 
 If this value is nil, the behavior is equivalent to the Honor policy. This is a beta-level feature default enabled by the NodeInclusionPolicyInPodTopologySpread feature flag.

| `nodeTaintsPolicy`
| `string`
| NodeTaintsPolicy indicates how we will treat node taints when calculating pod topology spread skew. Options are: - Honor: nodes without taints, along with tainted nodes for which the incoming pod has a toleration, are included. - Ignore: node taints are ignored. All nodes are included. 
 If this value is nil, the behavior is equivalent to the Ignore policy. This is a beta-level feature default enabled by the NodeInclusionPolicyInPodTopologySpread feature flag.

| `topologyKey`
| `string`
| TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each <key, value> as a "bucket", and try to put balanced number of pods into each bucket. We define a domain as a particular instance of a topology. Also, we define an eligible domain as a domain whose nodes meet the requirements of nodeAffinityPolicy and nodeTaintsPolicy. e.g. If TopologyKey is "kubernetes.io/hostname", each Node is a domain of that topology. And, if TopologyKey is "topology.kubernetes.io/zone", each zone is a domain of that topology. It's a required field.

| `whenUnsatisfiable`
| `string`
| WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it. - ScheduleAnyway tells the scheduler to schedule the pod in any location, but giving higher precedence to topologies that would help reduce the skew. A constraint is considered "Unsatisfiable" for an incoming pod if and only if every possible node assignment for that pod would violate "MaxSkew" on some topology. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: \| zone1 \| zone2 \| zone3 \| \| P P P \|   P   \|   P   \| If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field.

|===
=== .spec.api.topology_spread_constraints[].labelSelector
Description::
+
--
LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.api.topology_spread_constraints[].labelSelector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.api.topology_spread_constraints[].labelSelector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.chatbot_api
Description::
+
--
Defines desired state of the resources
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `node_selector`
| `object (string)`
| NodeSelector for the pods.

| `replicas`
| ``
| The number of replicas. Default: 1

| `resource_requirements`
| `object`
| Resource requirements for the container.

| `strategy`
| `object`
| The deployment strategy to use to replace existing pods with new ones.

| `tolerations`
| `array`
| Node tolerations for the pods.

| `tolerations[]`
| `object`
| The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.

| `topology_spread_constraints`
| `array`
| Topology rule(s) for the pods.

| `topology_spread_constraints[]`
| `object`
| TopologySpreadConstraint specifies how to spread matching pods among the given topology.

|===
=== .spec.chatbot_api.resource_requirements
Description::
+
--
Resource requirements for the container.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `claims`
| `array`
| Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
 This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
 This field is immutable.

| `claims[]`
| `object`
| ResourceClaim references one entry in PodSpec.ResourceClaims.

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .spec.chatbot_api.resource_requirements.claims
Description::
+
--
Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
 This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
 This field is immutable.
--

Type::
  `array`




=== .spec.chatbot_api.resource_requirements.claims[]
Description::
+
--
ResourceClaim references one entry in PodSpec.ResourceClaims.
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.

|===
=== .spec.chatbot_api.strategy
Description::
+
--
The deployment strategy to use to replace existing pods with new ones.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `rollingUpdate`
| `object`
| Rolling update config params. Present only if DeploymentStrategyType = RollingUpdate. --- TODO: Update this to follow our convention for oneOf, whatever we decide it to be.

| `type`
| `string`
| Type of deployment. Can be "Recreate" or "RollingUpdate". Default is RollingUpdate.

|===
=== .spec.chatbot_api.strategy.rollingUpdate
Description::
+
--
Rolling update config params. Present only if DeploymentStrategyType = RollingUpdate. --- TODO: Update this to follow our convention for oneOf, whatever we decide it to be.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `maxSurge`
| `integer-or-string`
| The maximum number of pods that can be scheduled above the desired number of pods. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number is calculated from percentage by rounding up. Defaults to 25%. Example: when this is set to 30%, the new ReplicaSet can be scaled up immediately when the rolling update starts, such that the total number of old and new pods do not exceed 130% of desired pods. Once old pods have been killed, new ReplicaSet can be scaled up further, ensuring that total number of pods running at any time during the update is at most 130% of desired pods.

| `maxUnavailable`
| `integer-or-string`
| The maximum number of pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). Absolute number is calculated from percentage by rounding down. This can not be 0 if MaxSurge is 0. Defaults to 25%. Example: when this is set to 30%, the old ReplicaSet can be scaled down to 70% of desired pods immediately when the rolling update starts. Once new pods are ready, old ReplicaSet can be scaled down further, followed by scaling up the new ReplicaSet, ensuring that the total number of pods available at all times during the update is at least 70% of desired pods.

|===
=== .spec.chatbot_api.tolerations
Description::
+
--
Node tolerations for the pods.
--

Type::
  `array`




=== .spec.chatbot_api.tolerations[]
Description::
+
--
The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `effect`
| `string`
| Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.

| `key`
| `string`
| Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.

| `operator`
| `string`
| Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.

| `tolerationSeconds`
| `integer`
| TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.

| `value`
| `string`
| Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.

|===
=== .spec.chatbot_api.topology_spread_constraints
Description::
+
--
Topology rule(s) for the pods.
--

Type::
  `array`




=== .spec.chatbot_api.topology_spread_constraints[]
Description::
+
--
TopologySpreadConstraint specifies how to spread matching pods among the given topology.
--

Type::
  `object`

Required::
  - `maxSkew`
  - `topologyKey`
  - `whenUnsatisfiable`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `labelSelector`
| `object`
| LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.

| `matchLabelKeys`
| `array (string)`
| MatchLabelKeys is a set of pod label keys to select the pods over which spreading will be calculated. The keys are used to lookup values from the incoming pod labels, those key-value labels are ANDed with labelSelector to select the group of existing pods over which spreading will be calculated for the incoming pod. Keys that don't exist in the incoming pod labels will be ignored. A null or empty list means only match against labelSelector.

| `maxSkew`
| `integer`
| MaxSkew describes the degree to which pods may be unevenly distributed. When `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference between the number of matching pods in the target topology and the global minimum. The global minimum is the minimum number of matching pods in an eligible domain or zero if the number of eligible domains is less than MinDomains. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 2/2/1: In this case, the global minimum is 1. \| zone1 \| zone2 \| zone3 \| \|  P P  \|  P P  \|   P   \| - if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2; scheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2) violate MaxSkew(1). - if MaxSkew is 2, incoming pod can be scheduled onto any zone. When `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence to topologies that satisfy it. It's a required field. Default value is 1 and 0 is not allowed.

| `minDomains`
| `integer`
| MinDomains indicates a minimum number of eligible domains. When the number of eligible domains with matching topology keys is less than minDomains, Pod Topology Spread treats "global minimum" as 0, and then the calculation of Skew is performed. And when the number of eligible domains with matching topology keys equals or greater than minDomains, this value has no effect on scheduling. As a result, when the number of eligible domains is less than minDomains, scheduler won't schedule more than maxSkew Pods to those domains. If value is nil, the constraint behaves as if MinDomains is equal to 1. Valid values are integers greater than 0. When value is not nil, WhenUnsatisfiable must be DoNotSchedule. 
 For example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same labelSelector spread as 2/2/2: \| zone1 \| zone2 \| zone3 \| \|  P P  \|  P P  \|  P P  \| The number of domains is less than 5(MinDomains), so "global minimum" is treated as 0. In this situation, new pod with the same labelSelector cannot be scheduled, because computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones, it will violate MaxSkew. 
 This is a beta field and requires the MinDomainsInPodTopologySpread feature gate to be enabled (enabled by default).

| `nodeAffinityPolicy`
| `string`
| NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector when calculating pod topology spread skew. Options are: - Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations. - Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations. 
 If this value is nil, the behavior is equivalent to the Honor policy. This is a beta-level feature default enabled by the NodeInclusionPolicyInPodTopologySpread feature flag.

| `nodeTaintsPolicy`
| `string`
| NodeTaintsPolicy indicates how we will treat node taints when calculating pod topology spread skew. Options are: - Honor: nodes without taints, along with tainted nodes for which the incoming pod has a toleration, are included. - Ignore: node taints are ignored. All nodes are included. 
 If this value is nil, the behavior is equivalent to the Ignore policy. This is a beta-level feature default enabled by the NodeInclusionPolicyInPodTopologySpread feature flag.

| `topologyKey`
| `string`
| TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each <key, value> as a "bucket", and try to put balanced number of pods into each bucket. We define a domain as a particular instance of a topology. Also, we define an eligible domain as a domain whose nodes meet the requirements of nodeAffinityPolicy and nodeTaintsPolicy. e.g. If TopologyKey is "kubernetes.io/hostname", each Node is a domain of that topology. And, if TopologyKey is "topology.kubernetes.io/zone", each zone is a domain of that topology. It's a required field.

| `whenUnsatisfiable`
| `string`
| WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it. - ScheduleAnyway tells the scheduler to schedule the pod in any location, but giving higher precedence to topologies that would help reduce the skew. A constraint is considered "Unsatisfiable" for an incoming pod if and only if every possible node assignment for that pod would violate "MaxSkew" on some topology. For example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same labelSelector spread as 3/1/1: \| zone1 \| zone2 \| zone3 \| \| P P P \|   P   \|   P   \| If WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled to zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies MaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler won't make it *more* imbalanced. It's a required field.

|===
=== .spec.chatbot_api.topology_spread_constraints[].labelSelector
Description::
+
--
LabelSelector is used to find matching pods. Pods that match this label selector are counted to determine the number of pods in their corresponding topology domain.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `matchExpressions`
| `array`
| matchExpressions is a list of label selector requirements. The requirements are ANDed.

| `matchExpressions[]`
| `object`
| A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.

| `matchLabels`
| `object (string)`
| matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels map is equivalent to an element of matchExpressions, whose key field is "key", the operator is "In", and the values array contains only "value". The requirements are ANDed.

|===
=== .spec.chatbot_api.topology_spread_constraints[].labelSelector.matchExpressions
Description::
+
--
matchExpressions is a list of label selector requirements. The requirements are ANDed.
--

Type::
  `array`




=== .spec.chatbot_api.topology_spread_constraints[].labelSelector.matchExpressions[]
Description::
+
--
A label selector requirement is a selector that contains values, a key, and an operator that relates the key and values.
--

Type::
  `object`

Required::
  - `key`
  - `operator`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `key`
| `string`
| key is the label key that the selector applies to.

| `operator`
| `string`
| operator represents a key's relationship to a set of values. Valid operators are In, NotIn, Exists and DoesNotExist.

| `values`
| `array (string)`
| values is an array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. This array is replaced during a strategic merge patch.

|===
=== .spec.database
Description::
+
--
The PostgreSQL database StatefulSet
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `database_secret`
| `string`
| Secret where the database configuration can be found. Set this to use your own external PostgreSQL database. If not specified, this secret will be generated and a managed pod will not be created

| `node_selector`
| `object (string)`
| NodeSelector for the database pod.

| `postgres_data_volume_init`
| `boolean`
| Sets permissions on the /var/lib/pgdata/data for postgres container using an init container (not Openshift)

| `postgres_extra_args`
| `array (string)`
| Arguments to pass to postgres process

| `postgres_init_container_commands`
| `string`
| Customize the postgres init container commands (Non Openshift)

| `postgres_keep_pvc_after_upgrade`
| `boolean`
| Specify whether or not to keep the old PVC after PostgreSQL upgrades

| `postgres_ssl_mode`
| `string`
| Configure PostgreSQL connection sslmode option. Default: "prefer"

| `postgres_storage_class`
| `string`
| Storage class to use for the PostgreSQL PVC

| `priority_class`
| `string`
| Assign a pre-existing priority class to the postgres pod

| `resource_requirements`
| `object`
| Resource requirements for the database container.

| `storage_requirements`
| `object`
| Storage requirements for the PostgreSQL container

| `tolerations`
| `array`
| Node tolerations for the database pod.

| `tolerations[]`
| `object`
| The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.

|===
=== .spec.database.resource_requirements
Description::
+
--
Resource requirements for the database container.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `claims`
| `array`
| Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
 This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
 This field is immutable.

| `claims[]`
| `object`
| ResourceClaim references one entry in PodSpec.ResourceClaims.

| `limits`
| `integer-or-string`
| Limits describes the maximum amount of compute resources allowed. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

| `requests`
| `integer-or-string`
| Requests describes the minimum amount of compute resources required. If Requests is omitted for a container, it defaults to Limits if that is explicitly specified, otherwise to an implementation-defined value. More info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/

|===
=== .spec.database.resource_requirements.claims
Description::
+
--
Claims lists the names of resources, defined in spec.resourceClaims, that are used by this container. 
 This is an alpha field and requires enabling the DynamicResourceAllocation feature gate. 
 This field is immutable.
--

Type::
  `array`




=== .spec.database.resource_requirements.claims[]
Description::
+
--
ResourceClaim references one entry in PodSpec.ResourceClaims.
--

Type::
  `object`

Required::
  - `name`



[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `name`
| `string`
| Name must match the name of one entry in pod.spec.resourceClaims of the Pod where this field is used. It makes that resource available inside a container.

|===
=== .spec.database.storage_requirements
Description::
+
--
Storage requirements for the PostgreSQL container
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `limits`
| `object`
| 

| `requests`
| `object`
| 

|===
=== .spec.database.storage_requirements.limits
Description::
+
--

--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `storage`
| `string`
| 

|===
=== .spec.database.storage_requirements.requests
Description::
+
--

--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `storage`
| `string`
| 

|===
=== .spec.database.tolerations
Description::
+
--
Node tolerations for the database pod.
--

Type::
  `array`




=== .spec.database.tolerations[]
Description::
+
--
The pod this Toleration is attached to tolerates any taint that matches the triple <key,value,effect> using the matching operator <operator>.
--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `effect`
| `string`
| Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute.

| `key`
| `string`
| Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.

| `operator`
| `string`
| Operator represents a key's relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a pod can tolerate all taints of a particular category.

| `tolerationSeconds`
| `integer`
| TolerationSeconds represents the period of time the toleration (which must be of effect NoExecute, otherwise this field is ignored) tolerates the taint. By default, it is not set, which means tolerate the taint forever (do not evict). Zero and negative values will be treated as 0 (evict immediately) by the system.

| `value`
| `string`
| Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.

|===
=== .spec.extra_settings
Description::
+
--
Environment variables to configure the application-level settings
--

Type::
  `array`




=== .spec.extra_settings[]
Description::
+
--

--

Type::
  `object`




[cols="1,1,1",options="header"]
|===
| Property | Type | Description

| `setting`
| `string`
| 

| `value`
| ``
| 

|===

== API endpoints

The following API endpoints are available:

* `/apis/lightspeed.ansible.com/v1alpha1/ansiblelightspeeds`
- `GET`: list objects of kind AnsibleLightspeed
* `/apis/lightspeed.ansible.com/v1alpha1/namespaces/{namespace}/ansiblelightspeeds`
- `DELETE`: delete collection of AnsibleLightspeed
- `GET`: list objects of kind AnsibleLightspeed
- `POST`: create an AnsibleLightspeed
* `/apis/lightspeed.ansible.com/v1alpha1/namespaces/{namespace}/ansiblelightspeeds/{name}`
- `DELETE`: delete an AnsibleLightspeed
- `GET`: read the specified AnsibleLightspeed
- `PATCH`: partially update the specified AnsibleLightspeed
- `PUT`: replace the specified AnsibleLightspeed
* `/apis/lightspeed.ansible.com/v1alpha1/namespaces/{namespace}/ansiblelightspeeds/{name}/status`
- `GET`: read status of the specified AnsibleLightspeed
- `PATCH`: partially update status of the specified AnsibleLightspeed
- `PUT`: replace status of the specified AnsibleLightspeed


=== /apis/lightspeed.ansible.com/v1alpha1/ansiblelightspeeds


.Global query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `allowWatchBookmarks`
| `boolean`
| allowWatchBookmarks requests watch events with type &quot;BOOKMARK&quot;. Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server&#x27;s discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored.
| `continue`
| `string`
| The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the &quot;next key&quot;.

This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
| `fieldSelector`
| `string`
| A selector to restrict the list of returned objects by their fields. Defaults to everything.
| `labelSelector`
| `string`
| A selector to restrict the list of returned objects by their labels. Defaults to everything.
| `limit`
| `integer`
| limit is a maximum number of responses to return for a list call. If more items exist, the server will set the &#x60;continue&#x60; field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.

The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
| `pretty`
| `string`
| If &#x27;true&#x27;, then the output is pretty printed.
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `resourceVersionMatch`
| `string`
| resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `sendInitialEvents`
| `boolean`
| &#x60;sendInitialEvents&#x3D;true&#x60; may be set together with &#x60;watch&#x3D;true&#x60;. In that case, the watch stream will begin with synthetic events to produce the current state of objects in the collection. Once all such events have been sent, a synthetic &quot;Bookmark&quot; event  will be sent. The bookmark will report the ResourceVersion (RV) corresponding to the set of objects, and be marked with &#x60;&quot;k8s.io/initial-events-end&quot;: &quot;true&quot;&#x60; annotation. Afterwards, the watch stream will proceed as usual, sending watch events corresponding to changes (subsequent to the RV) to objects watched.

When &#x60;sendInitialEvents&#x60; option is set, we require &#x60;resourceVersionMatch&#x60; option to also be set. The semantic of the watch request is as following: - &#x60;resourceVersionMatch&#x60; &#x3D; NotOlderThan
  is interpreted as &quot;data at least as new as the provided &#x60;resourceVersion&#x60;&quot;
  and the bookmark event is send when the state is synced
  to a &#x60;resourceVersion&#x60; at least as fresh as the one provided by the ListOptions.
  If &#x60;resourceVersion&#x60; is unset, this is interpreted as &quot;consistent read&quot; and the
  bookmark event is send when the state is synced at least to the moment
  when request started being processed.
- &#x60;resourceVersionMatch&#x60; set to any other value or unset
  Invalid error is returned.

Defaults to true if &#x60;resourceVersion&#x3D;&quot;&quot;&#x60; or &#x60;resourceVersion&#x3D;&quot;0&quot;&#x60; (for backward compatibility reasons) and to false otherwise.
| `timeoutSeconds`
| `integer`
| Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
| `watch`
| `boolean`
| Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
|===

HTTP method::
  `GET`

Description::
  list objects of kind AnsibleLightspeed


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../objects/index.adoc#com.ansible.lightspeed.v1alpha1.AnsibleLightspeedList[`AnsibleLightspeedList`] schema
| 401 - Unauthorized
| Empty
|===


=== /apis/lightspeed.ansible.com/v1alpha1/namespaces/{namespace}/ansiblelightspeeds

.Global path parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `namespace`
| `string`
| object name and auth scope, such as for teams and projects
|===

.Global query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `pretty`
| `string`
| If &#x27;true&#x27;, then the output is pretty printed.
|===

HTTP method::
  `DELETE`

Description::
  delete collection of AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `allowWatchBookmarks`
| `boolean`
| allowWatchBookmarks requests watch events with type &quot;BOOKMARK&quot;. Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server&#x27;s discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored.
| `continue`
| `string`
| The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the &quot;next key&quot;.

This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
| `fieldSelector`
| `string`
| A selector to restrict the list of returned objects by their fields. Defaults to everything.
| `labelSelector`
| `string`
| A selector to restrict the list of returned objects by their labels. Defaults to everything.
| `limit`
| `integer`
| limit is a maximum number of responses to return for a list call. If more items exist, the server will set the &#x60;continue&#x60; field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.

The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `resourceVersionMatch`
| `string`
| resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `sendInitialEvents`
| `boolean`
| &#x60;sendInitialEvents&#x3D;true&#x60; may be set together with &#x60;watch&#x3D;true&#x60;. In that case, the watch stream will begin with synthetic events to produce the current state of objects in the collection. Once all such events have been sent, a synthetic &quot;Bookmark&quot; event  will be sent. The bookmark will report the ResourceVersion (RV) corresponding to the set of objects, and be marked with &#x60;&quot;k8s.io/initial-events-end&quot;: &quot;true&quot;&#x60; annotation. Afterwards, the watch stream will proceed as usual, sending watch events corresponding to changes (subsequent to the RV) to objects watched.

When &#x60;sendInitialEvents&#x60; option is set, we require &#x60;resourceVersionMatch&#x60; option to also be set. The semantic of the watch request is as following: - &#x60;resourceVersionMatch&#x60; &#x3D; NotOlderThan
  is interpreted as &quot;data at least as new as the provided &#x60;resourceVersion&#x60;&quot;
  and the bookmark event is send when the state is synced
  to a &#x60;resourceVersion&#x60; at least as fresh as the one provided by the ListOptions.
  If &#x60;resourceVersion&#x60; is unset, this is interpreted as &quot;consistent read&quot; and the
  bookmark event is send when the state is synced at least to the moment
  when request started being processed.
- &#x60;resourceVersionMatch&#x60; set to any other value or unset
  Invalid error is returned.

Defaults to true if &#x60;resourceVersion&#x3D;&quot;&quot;&#x60; or &#x60;resourceVersion&#x3D;&quot;0&quot;&#x60; (for backward compatibility reasons) and to false otherwise.
| `timeoutSeconds`
| `integer`
| Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
| `watch`
| `boolean`
| Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Status[`Status`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `GET`

Description::
  list objects of kind AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `allowWatchBookmarks`
| `boolean`
| allowWatchBookmarks requests watch events with type &quot;BOOKMARK&quot;. Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server&#x27;s discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored.
| `continue`
| `string`
| The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the &quot;next key&quot;.

This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
| `fieldSelector`
| `string`
| A selector to restrict the list of returned objects by their fields. Defaults to everything.
| `labelSelector`
| `string`
| A selector to restrict the list of returned objects by their labels. Defaults to everything.
| `limit`
| `integer`
| limit is a maximum number of responses to return for a list call. If more items exist, the server will set the &#x60;continue&#x60; field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.

The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `resourceVersionMatch`
| `string`
| resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
| `sendInitialEvents`
| `boolean`
| &#x60;sendInitialEvents&#x3D;true&#x60; may be set together with &#x60;watch&#x3D;true&#x60;. In that case, the watch stream will begin with synthetic events to produce the current state of objects in the collection. Once all such events have been sent, a synthetic &quot;Bookmark&quot; event  will be sent. The bookmark will report the ResourceVersion (RV) corresponding to the set of objects, and be marked with &#x60;&quot;k8s.io/initial-events-end&quot;: &quot;true&quot;&#x60; annotation. Afterwards, the watch stream will proceed as usual, sending watch events corresponding to changes (subsequent to the RV) to objects watched.

When &#x60;sendInitialEvents&#x60; option is set, we require &#x60;resourceVersionMatch&#x60; option to also be set. The semantic of the watch request is as following: - &#x60;resourceVersionMatch&#x60; &#x3D; NotOlderThan
  is interpreted as &quot;data at least as new as the provided &#x60;resourceVersion&#x60;&quot;
  and the bookmark event is send when the state is synced
  to a &#x60;resourceVersion&#x60; at least as fresh as the one provided by the ListOptions.
  If &#x60;resourceVersion&#x60; is unset, this is interpreted as &quot;consistent read&quot; and the
  bookmark event is send when the state is synced at least to the moment
  when request started being processed.
- &#x60;resourceVersionMatch&#x60; set to any other value or unset
  Invalid error is returned.

Defaults to true if &#x60;resourceVersion&#x3D;&quot;&quot;&#x60; or &#x60;resourceVersion&#x3D;&quot;0&quot;&#x60; (for backward compatibility reasons) and to false otherwise.
| `timeoutSeconds`
| `integer`
| Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
| `watch`
| `boolean`
| Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../objects/index.adoc#com.ansible.lightspeed.v1alpha1.AnsibleLightspeedList[`AnsibleLightspeedList`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `POST`

Description::
  create an AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default in v1.23+ - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 201 - Created
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 202 - Accepted
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 401 - Unauthorized
| Empty
|===


=== /apis/lightspeed.ansible.com/v1alpha1/namespaces/{namespace}/ansiblelightspeeds/{name}

.Global path parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `name`
| `string`
| name of the AnsibleLightspeed
| `namespace`
| `string`
| object name and auth scope, such as for teams and projects
|===

.Global query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `pretty`
| `string`
| If &#x27;true&#x27;, then the output is pretty printed.
|===

HTTP method::
  `DELETE`

Description::
  delete an AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `gracePeriodSeconds`
| `integer`
| The duration in seconds before the object should be deleted. Value must be non-negative integer. The value zero indicates delete immediately. If this value is nil, the default grace period for the specified type will be used. Defaults to a per object value if not specified. zero means delete immediately.
| `orphanDependents`
| `boolean`
| Deprecated: please use the PropagationPolicy, this field will be deprecated in 1.7. Should the dependent objects be orphaned. If true/false, the &quot;orphan&quot; finalizer will be added to/removed from the object&#x27;s finalizers list. Either this field or PropagationPolicy may be set, but not both.
| `propagationPolicy`
| `string`
| Whether and how garbage collection will be performed. Either this field or OrphanDependents may be set, but not both. The default policy is decided by the existing finalizer set in the metadata.finalizers and the resource-specific default policy. Acceptable values are: &#x27;Orphan&#x27; - orphan the dependents; &#x27;Background&#x27; - allow the garbage collector to delete the dependents in the background; &#x27;Foreground&#x27; - a cascading policy that deletes all dependents in the foreground.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.DeleteOptions[`DeleteOptions`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Status[`Status`] schema
| 202 - Accepted
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Status[`Status`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `GET`

Description::
  read the specified AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PATCH`

Description::
  partially update the specified AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default in v1.23+ - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
| `force`
| `boolean`
| Force is going to &quot;force&quot; Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Patch[`Patch`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PUT`

Description::
  replace the specified AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default in v1.23+ - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 201 - Created
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 401 - Unauthorized
| Empty
|===


=== /apis/lightspeed.ansible.com/v1alpha1/namespaces/{namespace}/ansiblelightspeeds/{name}/status

.Global path parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `name`
| `string`
| name of the AnsibleLightspeed
| `namespace`
| `string`
| object name and auth scope, such as for teams and projects
|===

.Global query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `pretty`
| `string`
| If &#x27;true&#x27;, then the output is pretty printed.
|===

HTTP method::
  `GET`

Description::
  read status of the specified AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `resourceVersion`
| `string`
| resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.

Defaults to unset
|===


.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PATCH`

Description::
  partially update status of the specified AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint. This field is required for apply requests (application/apply-patch) but optional for non-apply patch types (JsonPatch, MergePatch, StrategicMergePatch).
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default in v1.23+ - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
| `force`
| `boolean`
| Force is going to &quot;force&quot; Apply requests. It means user will re-acquire conflicting fields owned by other people. Force flag must be unset for non-apply patch requests.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../objects/index.adoc#io.k8s.apimachinery.pkg.apis.meta.v1.Patch[`Patch`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 401 - Unauthorized
| Empty
|===

HTTP method::
  `PUT`

Description::
  replace status of the specified AnsibleLightspeed


.Query parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `dryRun`
| `string`
| When present, indicates that modifications should not be persisted. An invalid or unrecognized dryRun directive will result in an error response and no further processing of the request. Valid values are: - All: all dry run stages will be processed
| `fieldManager`
| `string`
| fieldManager is a name associated with the actor or entity that is making these changes. The value must be less than or 128 characters long, and only contain printable characters, as defined by https://golang.org/pkg/unicode/#IsPrint.
| `fieldValidation`
| `string`
| fieldValidation instructs the server on how to handle objects in the request (POST/PUT/PATCH) containing unknown or duplicate fields. Valid values are: - Ignore: This will ignore any unknown fields that are silently dropped from the object, and will ignore all but the last duplicate field that the decoder encounters. This is the default behavior prior to v1.23. - Warn: This will send a warning via the standard warning response header for each unknown field that is dropped from the object, and for each duplicate field that is encountered. The request will still succeed if there are no other errors, and will only persist the last of any duplicate fields. This is the default in v1.23+ - Strict: This will fail the request with a BadRequest error if any unknown fields would be dropped from the object, or if any duplicate fields are present. The error returned from the server will contain all unknown and duplicate fields encountered.
|===

.Body parameters
[cols="1,1,2",options="header"]
|===
| Parameter | Type | Description
| `body`
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 
|===

.HTTP responses
[cols="1,1",options="header"]
|===
| HTTP code | Reponse body
| 200 - OK
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 201 - Created
| xref:../lightspeed_ansible_com/ansiblelightspeed-lightspeed-ansible-com-v1alpha1.adoc#ansiblelightspeed-lightspeed-ansible-com-v1alpha1[`AnsibleLightspeed`] schema
| 401 - Unauthorized
| Empty
|===


